{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85518866-1a01-4ccd-91e7-0af56839ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61c91f7-3631-4443-b071-14d6afe81860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m847.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/rjaswal1634/.local/lib/python3.12/site-packages (from timm) (2.6.0)\n",
      "Collecting torchvision (from timm)\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from timm) (6.0.1)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /home/rjaswal1634/.local/lib/python3.12/site-packages (from huggingface_hub->timm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from huggingface_hub->timm) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/python3/dist-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from huggingface_hub->timm) (4.13.1)\n",
      "Requirement already satisfied: networkx in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch->timm) (68.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rjaswal1634/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/rjaswal1634/.local/lib/python3.12/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision->timm) (10.2.0)\n",
      "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface_hub, torchvision, timm\n",
      "Successfully installed huggingface_hub-0.30.2 safetensors-0.5.3 timm-1.0.15 torchvision-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ef2b25-24b7-4c8a-851b-09dae5589b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Training dataset size: 4973 images\n",
      "Validation dataset size: 704 images\n",
      "Test dataset size: 699 images\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "print(\"Starting\")\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets with updated paths\n",
    "train_dataset = ImageFolder(\"processed_data/train\", transform=train_transform)\n",
    "val_dataset = ImageFolder(\"processed_data/val\", transform=val_transform)\n",
    "test_dataset = ImageFolder(\"processed_data/test\", transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Verify dataset sizes\n",
    "print(f\"Training dataset size: {len(train_dataset)} images\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)} images\")\n",
    "print(f\"Test dataset size: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c39e29-1827-4227-84d5-551fa5de7be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "class EfficientNetWithSepConv(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        # Load the base model\n",
    "        self.base = timm.create_model(\"efficientnet_b0\", pretrained=True, features_only=False)\n",
    "        \n",
    "        # Extract the features before the classifier\n",
    "        self.base.classifier = nn.Identity()\n",
    "        self.base.global_pool = nn.Identity()\n",
    "        \n",
    "        # Define input features for the separable convolution\n",
    "        in_features = 1280\n",
    "        \n",
    "        self.sep_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, groups=in_features, padding=1),\n",
    "            nn.Conv2d(in_features, 256, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Use the forward method without accessing .features\n",
    "        x = self.base(x)\n",
    "        # At this point, x should be the output from the EfficientNet's feature extractor\n",
    "        x = self.sep_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea2a7c3-8d18-4fdf-83aa-e39d3519d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetWithSepConv(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30db6b96-c55b-48d4-b6a8-c9526f1988bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Epoch 1, Loss: 0.11374355015085222\n",
      "Validation Accuracy: 99.72%\n",
      "Epoch 2, Loss: 0.04506056896785501\n",
      "Validation Accuracy: 99.43%\n",
      "Epoch 3, Loss: 0.028044003826858573\n",
      "Validation Accuracy: 99.86%\n",
      "Epoch 4, Loss: 0.008581491304143221\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 5, Loss: 0.006322288504727625\n",
      "Validation Accuracy: 99.86%\n",
      "Epoch 6, Loss: 0.013474725819343383\n",
      "Validation Accuracy: 99.15%\n",
      "Epoch 7, Loss: 0.04304460089191801\n",
      "Validation Accuracy: 99.86%\n",
      "Epoch 8, Loss: 0.017923897613983195\n",
      "Validation Accuracy: 99.72%\n",
      "Epoch 9, Loss: 0.012614168230636725\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 10, Loss: 0.020192312994764414\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 11, Loss: 0.0183711491676709\n",
      "Validation Accuracy: 99.72%\n",
      "Epoch 12, Loss: 0.009748825637964332\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 13, Loss: 0.0065728919873366135\n",
      "Validation Accuracy: 99.72%\n",
      "Epoch 14, Loss: 0.004823576906693607\n",
      "Validation Accuracy: 99.86%\n",
      "Epoch 15, Loss: 0.0008573224632784378\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 16, Loss: 0.00507961580150643\n",
      "Validation Accuracy: 99.86%\n",
      "Epoch 17, Loss: 0.025768200434582375\n",
      "Validation Accuracy: 99.72%\n",
      "Epoch 18, Loss: 0.02406547270682215\n",
      "Validation Accuracy: 99.86%\n",
      "Epoch 19, Loss: 0.0081705462400397\n",
      "Validation Accuracy: 99.86%\n",
      "Epoch 20, Loss: 0.007569993118231184\n",
      "Validation Accuracy: 99.86%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Starting\")\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9989ad70-0476-4911-8ff6-832bdef60e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.86%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6f5ecc-64ea-4ddb-ab65-ab6fb3051eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cloudy       0.99      1.00      1.00       150\n",
      "      desert       1.00      1.00      1.00       249\n",
      "  green_area       1.00      1.00      1.00       150\n",
      "       water       1.00      1.00      1.00       150\n",
      "\n",
      "    accuracy                           1.00       699\n",
      "   macro avg       1.00      1.00      1.00       699\n",
      "weighted avg       1.00      1.00      1.00       699\n",
      "\n",
      "Accuracy for cloudy: 100.00%\n",
      "Accuracy for desert: 99.60%\n",
      "Accuracy for green_area: 100.00%\n",
      "Accuracy for water: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Collect predictions and labels from the test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Generate classification report\n",
    "class_names = [\"cloudy\", \"desert\", \"green_area\", \"water\"]\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# Compute per-class accuracy\n",
    "per_class_accuracy = {}\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_correct = sum((np.array(all_labels) == i) & (np.array(all_preds) == i))\n",
    "    class_total = sum(np.array(all_labels) == i)\n",
    "    per_class_accuracy[class_name] = 100 * class_correct / class_total\n",
    "    print(f\"Accuracy for {class_name}: {per_class_accuracy[class_name]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6060ba2b-d42f-4d8f-a9da-3f59ff8fb518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
