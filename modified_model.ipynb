{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d99b7e1-f525-4a7e-aff1-b2c0cec9aef5",
   "metadata": {},
   "source": [
    "# Doing Normalization and Setting up The batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ef2b25-24b7-4c8a-851b-09dae5589b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 4800 images\n",
      "Validation dataset size: 600 images\n",
      "Test dataset size: 600 images\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define normalization transformations\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "])\n",
    "\n",
    "# Load datasets with normalization (no augmentation)\n",
    "train_dataset = ImageFolder(\"processed_data/train\", transform=val_transform)\n",
    "val_dataset = ImageFolder(\"processed_data/val\", transform=val_transform)\n",
    "test_dataset = ImageFolder(\"processed_data/test\", transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Verify dataset sizes\n",
    "print(f\"Training dataset size: {len(train_dataset)} images\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)} images\")\n",
    "print(f\"Test dataset size: {len(test_dataset)} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7adc975-d4a1-4adb-b931-03a7df8320eb",
   "metadata": {},
   "source": [
    "# Define the Modified EfficientNet-B0 with Seperabale Convolution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551610f0-4022-4cdd-b45f-d0dec0573db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b01a1f-3fa5-4cc8-9195-62e7adfc4cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Making the model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "class EfficientNetWithSepConv(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        # Load the base model\n",
    "        self.base = timm.create_model(\"efficientnet_b0\", pretrained=True, features_only=False)\n",
    "        \n",
    "        # Extract the features before the classifier\n",
    "        self.base.classifier = nn.Identity()\n",
    "        self.base.global_pool = nn.Identity()\n",
    "        \n",
    "        # Define input features for the separable convolution\n",
    "        in_features = 1280\n",
    "        \n",
    "        self.sep_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, groups=in_features, padding=1),\n",
    "            nn.Conv2d(in_features, 256, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Use the forward method without accessing .features\n",
    "        x = self.base(x)\n",
    "        # At this point, x should be the output from the EfficientNet's feature extractor\n",
    "        x = self.sep_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "print(\"Done Making the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf46e1d-bc12-4c29-b37b-360684159d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Training setup model 1\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetWithSepConv(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca926146-9558-4867-8a94-722a087a47a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Epoch 1, Loss: 0.1569676517229527\n",
      "Validation Accuracy: 98.67%\n",
      "Epoch 2, Loss: 0.029325566313927992\n",
      "Validation Accuracy: 99.33%\n",
      "Epoch 3, Loss: 0.030279114949322925\n",
      "Validation Accuracy: 99.67%\n",
      "Epoch 4, Loss: 0.04014143187591496\n",
      "Validation Accuracy: 99.83%\n",
      "Epoch 5, Loss: 0.022460392838305174\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 6, Loss: 0.06556297233522249\n",
      "Validation Accuracy: 99.83%\n",
      "Epoch 7, Loss: 0.021629659482471954\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 8, Loss: 0.017802004612070352\n",
      "Validation Accuracy: 99.00%\n",
      "Epoch 9, Loss: 0.011953749310535689\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 10, Loss: 0.01038636947053116\n",
      "Validation Accuracy: 99.83%\n",
      "Epoch 11, Loss: 0.013526884691988622\n",
      "Validation Accuracy: 99.83%\n",
      "Epoch 12, Loss: 0.006001068068095871\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 13, Loss: 0.00175331908321823\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 14, Loss: 0.017002984463360918\n",
      "Validation Accuracy: 99.83%\n",
      "Epoch 15, Loss: 0.01136660850905173\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 16, Loss: 0.0038979652630829757\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 17, Loss: 0.009245189986019493\n",
      "Validation Accuracy: 99.50%\n",
      "Epoch 18, Loss: 0.024024466557420965\n",
      "Validation Accuracy: 99.83%\n",
      "Epoch 19, Loss: 0.013796991609512284\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 20, Loss: 0.011391211668766724\n",
      "Validation Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "print(\"Starting\")\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab0c4b1-47a6-4564-9e92-233cd9177d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'efficientnet_b0main_modified.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save Bare EfficientNet-B0 model\n",
    "torch.save(model.state_dict(), 'efficientnet_b0main_modified.pth')\n",
    "print(\"Model saved as 'efficientnet_b0main_modified.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9689a26c-c42d-43a8-9396-be8a9bb2c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 4349824\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming `model` is your trained or defined model\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {num_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d40ded-1c5b-44b4-b722-cfc5118fcc29",
   "metadata": {},
   "source": [
    "## 2nd Version of Modified Model with Less Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d06f7e1-cfcb-4a30-a515-4227457dde7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EfficientNetWithMinimalHead model class\n",
    "class EfficientNetWithMinimalHead(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.base = timm.create_model(\"efficientnet_b0\", pretrained=False, features_only=False)\n",
    "        self.base.classifier = nn.Identity()\n",
    "        self.base.global_pool = nn.Identity()\n",
    "        in_features = 1280\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(in_features, 4, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.fc = nn.Linear(4, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.head(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf085fa3-17d5-4398-bfb6-8b31b684bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "Starting\n",
      "Epoch 1, Loss: 0.9082540945212046\n",
      "Validation Accuracy: 90.33%\n",
      "Epoch 2, Loss: 0.711871751944224\n",
      "Validation Accuracy: 84.67%\n",
      "Epoch 3, Loss: 0.5662390170494715\n",
      "Validation Accuracy: 96.00%\n",
      "Epoch 4, Loss: 0.5029452804724376\n",
      "Validation Accuracy: 91.33%\n",
      "Epoch 5, Loss: 0.4319952137271563\n",
      "Validation Accuracy: 94.33%\n",
      "Epoch 6, Loss: 0.40523971418539684\n",
      "Validation Accuracy: 97.67%\n",
      "Epoch 7, Loss: 0.3710706571737925\n",
      "Validation Accuracy: 94.17%\n",
      "Epoch 8, Loss: 0.31484069883823396\n",
      "Validation Accuracy: 97.33%\n",
      "Epoch 9, Loss: 0.30416133468349776\n",
      "Validation Accuracy: 97.83%\n",
      "Epoch 10, Loss: 0.29930492838223777\n",
      "Validation Accuracy: 82.17%\n",
      "Epoch 11, Loss: 0.27724455766379835\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 12, Loss: 0.2496970512966315\n",
      "Validation Accuracy: 98.33%\n",
      "Epoch 13, Loss: 0.2345054562886556\n",
      "Validation Accuracy: 84.50%\n",
      "Epoch 14, Loss: 0.21707373936971028\n",
      "Validation Accuracy: 92.83%\n",
      "Epoch 15, Loss: 0.23218534072240193\n",
      "Validation Accuracy: 97.50%\n",
      "Epoch 16, Loss: 0.17872905902564526\n",
      "Validation Accuracy: 99.33%\n",
      "Epoch 17, Loss: 0.18362915597856044\n",
      "Validation Accuracy: 98.83%\n",
      "Epoch 18, Loss: 0.19097850824395815\n",
      "Validation Accuracy: 89.00%\n",
      "Epoch 19, Loss: 0.16543780215084553\n",
      "Validation Accuracy: 98.83%\n",
      "Epoch 20, Loss: 0.1579582866281271\n",
      "Validation Accuracy: 99.50%\n"
     ]
    }
   ],
   "source": [
    "# Training setup model 2\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_2 = EfficientNetWithMinimalHead(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "print(\"DONE\")\n",
    "\n",
    "# model 2\n",
    "print(\"Starting\")\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model_2.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_2(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation\n",
    "    model_2.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_2(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7da5e86f-1401-44e5-9d57-b77da17cc73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'efficientnet_b0_2_modified.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save Bare EfficientNet-B0 model\n",
    "torch.save(model_2.state_dict(), 'efficientnet_b0_2_modified.pth')\n",
    "print(\"Model saved as 'efficientnet_b0_2_modified.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e875b5-8700-4bb8-a2ef-79b0778bd5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
